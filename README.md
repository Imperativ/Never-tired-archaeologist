# Archaeologist v3.0 â€” Semantische Dokumentenanalyse mit Multi-Provider LLMs

Lokales Tool zur intelligenten Dokumentenanalyse mit KI-gestÃ¼tzter Metadatenextraktion, Embedding-Vektorisierung, Duplikaterkennung und Volltextsuche.

## ğŸš€ Features

### Core-FunktionalitÃ¤t

- **Tkinter-GUI** (Deutsch): Intuitive BenutzeroberflÃ¤che fÃ¼r alle Funktionen
- **Rekursiver Dateiscan**: UnterstÃ¼tzt `.txt`, `.md`, `.pdf`, `.py`, `.json`, `.csv`, `.html`
- **Multi-Provider LLM-Architektur**:
  - **Claude Haiku 4.5** (Anthropic): Schnelle, prÃ¤zise Metadaten-Analyse
  - **Gemini Embedding-001** (Google): Hochwertige Vektorisierung
- **SQLite-Datenbank mit FTS5**: Persistente Speicherung & blitzschnelle Volltextsuche
- **Duplikaterkennung**: Cosine-Similarity Ã¼ber Embeddings (Schwellwert: 0.95)
- **Volltext-Suche**: FTS5-basierte Suche direkt in der GUI
- **Optional**: Markdown-Export mit YAML-Frontmatter

### Metadaten-Extraktion

Die KI analysiert automatisch:

- Sprache (ISO 639-1 Code)
- Thema/Topic
- Keywords (Liste)
- Zusammenfassung
- LLM-Erkennung (ist_prompt, ist_llm_output)
- Git-Projekt-Erkennung
- Konfidenz-Score

### Datenbank-Schema

```
documents         â†’ Kerndokumente (Dateiname, Pfad, Text, Wortanzahl, etc.)
metadata          â†’ Extrahierte Metadaten (Sprache, Topic, Keywords, etc.)
embeddings        â†’ Vektorembeddings (768 Dimensionen, BLOB)
duplicates        â†’ Duplikat-Beziehungen
documents_fts     â†’ FTS5 Volltextindex
```

## ğŸ“¦ Installation

### Voraussetzungen

- Python 3.12+
- API-Keys fÃ¼r:
  - **Anthropic** (Claude)
  - **Google AI** (Gemini)

### Setup

```bash
# Repository klonen
git clone https://github.com/Imperativ/Never-tired-archaeologist.git
cd Never-tired-archaeologist

# Virtual Environment erstellen
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Dependencies installieren
pip install -r requirements.txt

# API-Keys konfigurieren
cp .env.example .env
# Trage deine API-Keys in .env ein (siehe unten)
```

### API-Keys Konfiguration

Erstelle eine `.env` Datei im Projektverzeichnis:

```env
# Anthropic API Key (fÃ¼r Claude Haiku 4.5)
ANTHROPIC_API_KEY=sk-ant-...

# Google AI API Key (fÃ¼r Gemini Embeddings)
GOOGLE_API_KEY=AIza...
# Alternative:
# GEMINI_API_KEY=AIza...
```

**API-Keys erhalten:**

- **Anthropic**: https://console.anthropic.com/
- **Google AI**: https://aistudio.google.com/app/apikey

## ğŸ¯ Verwendung

### GUI starten

```bash
python main.py
```

### Workflow

1. **Ordner auswÃ¤hlen**: Klicke auf "Ordner auswÃ¤hlen" und wÃ¤hle deinen Dokumentenordner
2. **Optionen konfigurieren**:
   - â˜‘ **Embeddings erzeugen** (empfohlen fÃ¼r Duplikaterkennung)
   - â˜ **Markdown-Dateien exportieren** (optional, da Datenbank primÃ¤r)
3. **Scannen**: Klicke auf "Scannen & Analysieren"
4. **Suchen**: Nutze das Suchfeld fÃ¼r Volltextsuche in der Datenbank
5. **Statistiken**: Zeige Datenbank-Statistiken an

### Suche

Die Volltextsuche unterstÃ¼tzt FTS5-Syntax:

```
# Einfache Suche
Python

# Boolean-Operatoren
Python AND tutorial

# Phrase-Suche
"machine learning"

# Ausschluss
Python NOT tutorial

# Kombiniert
(Python OR JavaScript) AND tutorial
```

### Datenbank-Speicherort

Die Datenbank wird automatisch im gewÃ¤hlten Quellordner erstellt:

```
/dein/ordner/
â”œâ”€â”€ archaeologist.db   â† Hier!
â”œâ”€â”€ dokument1.pdf
â”œâ”€â”€ dokument2.txt
â””â”€â”€ ...
```

## ğŸ“Š GUI-Ãœbersicht

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Archaeologist â€” Dokument-Analysator v3.0.0               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Quellordner: /pfad/zu/deinen/dokumenten                  â”‚
â”‚ [Ordner auswÃ¤hlen...]                                     â”‚
â”‚                                                           â”‚
â”‚ â˜‘ Embeddings erzeugen (empfohlen fÃ¼r Duplikaterkennung) â”‚
â”‚ â˜ ZusÃ¤tzlich Markdown-Dateien exportieren (optional)    â”‚
â”‚                                                           â”‚
â”‚ Suche in Datenbank:                                      â”‚
â”‚ [Suchbegriff eingeben...........................] [ğŸ”]   â”‚
â”‚                                                           â”‚
â”‚ [Scannen & Analysieren] [Statistiken] [Log leeren]      â”‚
â”‚                                                           â”‚
â”‚ Status: Bereit.                                          â”‚
â”‚                                                           â”‚
â”‚ Protokoll:                                               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚[12:34:56] Verarbeite: dokument.pdf                   â”‚â”‚
â”‚ â”‚[12:34:57]   â†’ Analysiere mit Claude Haiku 4.5...     â”‚â”‚
â”‚ â”‚[12:34:58]   â†’ Sprache: de, Topic: Finanzen           â”‚â”‚
â”‚ â”‚[12:34:58]   âœ“ In Datenbank gespeichert (ID: 42)     â”‚â”‚
â”‚ â”‚                                                       â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§ª Tests

Umfangreiche Test-Suite mit 214 Tests:

```bash
# Alle Tests ausfÃ¼hren
pytest tests/ -v

# Mit Coverage
pytest tests/ --cov=. --cov-report=html

# Nur spezifische Module
pytest tests/test_database.py -v
pytest tests/test_main.py -v
```

**Test-Coverage:**

- `database.py` - SQLite-Operationen, FTS5-Suche
- `dupdetect.py` - Cosine-Similarity, Duplikaterkennung
- `file_scanner.py` - Rekursiver Scan, Filterung
- `text_extractor.py` - Text-Extraktion (7 Formate)
- `exporter.py` - Markdown-Export, YAML-Escaping
- `llm_providers.py` - Multi-Provider-Architektur
- `main.py` - GUI-SuchfunktionalitÃ¤t
- `utils.py` - Hilfsfunktionen

## ğŸ—ï¸ Architektur

### Multi-Provider System

```python
MultiProvider
â”œâ”€â”€ ClaudeProvider (Analyse)
â”‚   â””â”€â”€ Claude Haiku 4.5 (schnell, kostengÃ¼nstig)
â””â”€â”€ GeminiProvider (Embeddings)
    â””â”€â”€ gemini-embedding-001 (768 Dimensionen)
```

**Vorteile:**

- **Austauschbar**: Provider kÃ¶nnen einfach gewechselt werden
- **Skalierbar**: Neue Provider Ã¼ber Abstract Base Classes hinzufÃ¼gen
- **Fallback-fÃ¤hig**: Bei Rate-Limits automatisch weitermachen

### Datenfluss

```
1. File Scanner  â†’  Dateien finden
2. Text Extractor  â†’  Text extrahieren
3. Claude Provider  â†’  Metadaten analysieren
4. Gemini Provider  â†’  Embedding generieren
5. Duplicate Detector  â†’  Duplikate finden
6. Database  â†’  Persistent speichern
7. (Optional) Exporter  â†’  Markdown exportieren
```

## ğŸ”’ Sicherheit

- **Lokale Verarbeitung**: Alle Daten bleiben auf deinem System
- **API-Keys**: Werden niemals im Code gespeichert, nur in `.env`
- **Keine Cloud-Speicherung**: Datenbank ist lokal (SQLite)
- **.env in .gitignore**: Keys werden nicht versioniert

## ğŸ“ Duplikaterkennung

Dokumente werden als Duplikate erkannt, wenn:

- Embeddings vorhanden sind
- Cosine-Similarity â‰¥ 0.95 (anpassbar in `main.py`: `SIM_THRESHOLD`)

**Duplikat-Markierung:**

```sql
SELECT d1.filename, d2.filename, dup.similarity_score
FROM duplicates dup
JOIN documents d1 ON dup.document_id = d1.id
JOIN documents d2 ON dup.duplicate_of_id = d2.id;
```

## ğŸ› ï¸ Entwicklung

### Projekt-Struktur

```
Never-tired-archaeologist/
â”œâ”€â”€ main.py                 # GUI & Hauptlogik
â”œâ”€â”€ database.py             # SQLite + FTS5
â”œâ”€â”€ llm_providers.py        # Multi-Provider-Architektur
â”œâ”€â”€ text_extractor.py       # Text-Extraktion
â”œâ”€â”€ file_scanner.py         # Rekursiver Scan
â”œâ”€â”€ dupdetect.py            # Duplikaterkennung
â”œâ”€â”€ exporter.py             # Markdown-Export
â”œâ”€â”€ utils.py                # Hilfsfunktionen
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .env.example            # API-Key-Vorlage
â”œâ”€â”€ pytest.ini              # Test-Konfiguration
â””â”€â”€ tests/                  # 214 Unit-Tests
    â”œâ”€â”€ test_database.py
    â”œâ”€â”€ test_llm_providers.py
    â”œâ”€â”€ test_main.py
    â””â”€â”€ ...
```

### Dependencies

```
anthropic>=0.40.0          # Claude API
google-generativeai>=0.8.3 # Gemini API
PyMuPDF>=1.24.0            # PDF-Extraktion
pytest>=8.0.0              # Testing
pytest-cov>=5.0.0          # Coverage
python-dotenv>=1.0.0       # .env Support
```

## ğŸš¨ Fehlerbehandlung

- **Rate-Limits**: Werden Ã¼bersprungen, Log-Warnung
- **Fehlende API-Keys**: Warnung beim Start
- **Korrupte Dateien**: Fehler werden protokolliert in `error_log.txt`
- **Encoding-Probleme**: Automatischer Fallback auf alternative Encodings

## ğŸ“ˆ Statistiken

Zeige Datenbank-Statistiken Ã¼ber den "Statistiken"-Button:

- Anzahl Dokumente
- Anzahl Embeddings
- Anzahl Duplikate
- Verteilung nach Sprachen
- Verteilung nach Dateitypen

## ğŸ¯ Use Cases

- **Dokumenten-Management**: GroÃŸe Sammlungen analysieren und durchsuchen
- **Forschung**: Paper, Artikel, Notizen kategorisieren
- **Code-Analyse**: Python-Projekte, Git-Repos scannen
- **Prompt-Engineering**: Prompts und LLM-Outputs klassifizieren
- **Duplikat-Bereinigung**: Ã„hnliche Dokumente identifizieren

## ğŸ“„ Lizenz

Dieses Projekt ist fÃ¼r den persÃ¶nlichen Gebrauch entwickelt.

## ğŸ¤ Beitragen

Aktuell keine externen Contributions vorgesehen (persÃ¶nliches Projekt).

## âš ï¸ Hinweise

- **PDF-Support**: BenÃ¶tigt `PyMuPDF` (automatisch installiert)
- **API-Kosten**: Claude Haiku 4.5 ist sehr kostengÃ¼nstig (~$0.25 pro Million Tokens Input)
- **Embeddings**: Gemini Embedding-001 ist kostenlos (bis zu bestimmten Limits)
- **Performance**: GroÃŸe Ordner (1000+ Dateien) kÃ¶nnen lÃ¤nger dauern
- **Datenbank-GrÃ¶ÃŸe**: Embeddings benÃ¶tigen ~3KB pro Dokument

## ğŸ”— Links

- **GitHub**: https://github.com/Imperativ/Never-tired-archaeologist
- **Anthropic Console**: https://console.anthropic.com/
- **Google AI Studio**: https://aistudio.google.com/

## ğŸ“ Support

Bei Fragen oder Problemen:

1. PrÃ¼fe die Logs im GUI
2. Schau in `error_log.txt` im Quellordner
3. Teste mit kleinem Ordner zuerst
4. Stelle sicher, dass API-Keys korrekt sind

---

**Version**: 3.0.0
**Letzte Aktualisierung**: Januar 2025
**Python-Version**: 3.12+
